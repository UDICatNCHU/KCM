"""KCM generating script

This script is used to generate KCM/TCM (Term correlated model).
The task is done by calling many other scripts
"""

import os
import queue
import subprocess
import time
import logging
import errno
import argparse

from pathlib import Path
from threading import Thread
from djangoApiDec.djangoApiDec import timing, removeInputFile

def remove_file_if_exist(file_name):
    """Remove file if it exist

    Args:
        file_name: name of the file to be removed
    """
    file = Path(file_name)
    if file.is_file():
        os.remove(file_name)

def get_args():
    """Return args"""

    parser = argparse.ArgumentParser(
        description='Generate KCM (correlation model).')
    parser.add_argument('-l', '--lang',choices=['eng', 'cht'],help='language, english or chinese (eng/cht)',
                        required=True)
    parser.add_argument('-i', '--input_dir',
                        help='input raw data directory (default: %(default)s)',
                        required=True)
    parser.add_argument('-o', '--out_dir',
                        help='output directory (default: %(default)s)',
                        required=True)
    parser.add_argument('-m', '--max_file_count',
                        help='maximum number of input files, 0 for no limit\n'
                             '(default: %(default)s)',
                        type=int, default=1)
    parser.add_argument('-tc', '--thread_count',
                        help='number of thread used (default: %(default)s)',
                        type=int, default=1)
    parser.add_argument('-k', '--keep_temp_files',
                        help='keep temporary files generated by the script\n'
                             '(default: %(default)s)',
                        action='store_true') # store_true 代表如果有加 -k 這個參數的話，得到的值就是true

    args = parser.parse_args()

    logging.basicConfig(format='%(levelname)s : %(asctime)s : %(message)s', filename='KCM_{}.log'.format(args.lang), level=logging.INFO)
    logging.info('Begin gen_kcm.py')
    logging.info('input {args.max_file_count} files, '
                 'output to {args.out_dir}, '
                 'maximum file count {args.max_file_count}, '
                 'use {args.thread_count} threads'.format(**locals()))

    return args


def get_source_file_list(args):
    """Generate list of term data source files

    Args:
        args: input arguments, use args.lang, args.max_file_count

    Returns:
        list of source files
    """

    file_list = []  # wiki files
    for (dir_path, dir_names, file_names) in os.walk(args.input_dir):
        for file_name in file_names:
            if args.max_file_count and len(file_list) >= args.max_file_count:
                break
            if file_name == '.DS_Store':  # for OS X
                continue
            file_list.append(os.path.join(dir_path, file_name))
            logging.info(
                'appended file {}'.format(os.path.join(dir_path, file_name)))

    if not file_list:
        logging.info('no file selected, end of script')
        exit()

    return file_list

@timing
def remove_symbols_tags(if_name, args):
    """Remove symbols and tags. Read input file, output to output file.

    Args:
        if_name: input file name
        args: input arguments, use args.out_dir, args.lang

    Returns:
        output file name
    """
    prefix = if_name.replace('/', '-').replace('_', '-')
    of_name = '{args.out_dir}/{prefix}_paragraph_{args.lang}'.format(**locals())
    remove_file_if_exist(of_name)

    subprocess.call(['python3', 'build/rm_symbols_tags_empty_lines.py',
                     '-i={}'.format(if_name), '-o={}'.format(of_name)])
    return of_name

@removeInputFile
@timing
def paragraphs_to_sentences(if_name, args):
    """Generate sentences from paragraphs. Read input file, output to output file

    Args:
        if_name: input file name
        args: input arguments, use args.out_dir, args.lang

    Returns:
        output file name
    """
    prefix = if_name.split('/')[-1].split('_')[0]
    of_name = '{args.out_dir}/{prefix}_sentences_{args.lang}'.format(**locals())
    remove_file_if_exist(of_name)
    script_file = 'build/paragraphs_to_sentences_{}.py'.format(args.lang)

    subprocess.call(['python3', script_file,
                     '-i', if_name, '-o', of_name])

    return of_name

@removeInputFile
@timing
def sentences_to_terms(if_name, args):
    """generate terms from sentences

    Args:
        if_name: input file name
        args: input arguments, use args.out_dir, args.lang

    Returns:
        output file name
    """
    prefix = if_name.split('/')[-1].split('_')[0]
    of_name = '{args.out_dir}/{prefix}_terms_{args.lang}'.format(**locals())
    remove_file_if_exist(of_name)
    script_file = 'build/sentences_to_terms_{}.py'.format(args.lang)

    subprocess.call(['python', script_file,
                     if_name, '-o', of_name, '-m', 'w', '-s', 'n'])

    return of_name

@removeInputFile
@timing
def terms_to_term_pairs(if_name, args):
    """Generate term pairs from terms.

    Args:
        if_name: input file name
        args: input arguments, use args.out_dir, args.lang

    Returns:
        output file name
    """
    of_name = '{args.out_dir}/{args.lang}.model'.format(**locals())
    remove_file_if_exist(of_name)
    script_file = 'build/terms_to_term_pair_freq.py'

    subprocess.call(['python3', script_file, '-i', if_name, '-o', of_name])


# http://stackoverflow.com/questions/13613336/python-concatenate-text-files
def join_terms_files(if_names, args):
    """Join terms files into one

    Args:
        if_names: input terms files names
        args: input arguments
    """
    of_name = '{args.out_dir}/terms_{args.lang}'.format(**locals())
    with open(of_name, 'w') as output_file:
        for if_name in if_names:
            with open(if_name, 'r') as input_file:
                for line in input_file:
                    output_file.write(line)

    return of_name


def gen_terms_file(if_name, args, o_list):
    """Generate terms file

    Args:
        if_name: input wiki source file name
        args: input arguments
        o_list: output list saving generated file name
    """
    of_name = remove_symbols_tags(if_name, args)
    of_name = paragraphs_to_sentences(of_name, args)
    of_name = sentences_to_terms(of_name, args)
    o_list.append(of_name)


def thread_job(input_file_queue, args, o_term_files):
    """Job to be done by thread (generate terms file)

    Args:
        input_file_queue: queue containing input files that needs processing
        args: input arguments
        o_term_files: list for outputting generated term file names
    """
    while True:
        if_name = input_file_queue.get()
        if if_name is None:
            break  # end of thread
        gen_terms_file(if_name, args, o_list=o_term_files)
        input_file_queue.task_done()


def main():
    """Main function"""
    args = get_args()
    if_list = get_source_file_list(args)

    term_files = []
    input_file_queue = queue.Queue()
    threads = []
    for i in range(args.thread_count):
        t = Thread(target=thread_job, args=(input_file_queue, args, term_files))
        t.start()
        threads.append(t)

    for if_name in if_list:
        input_file_queue.put(if_name)

    # block till all tasks are done (here means all input file processed)
    input_file_queue.join()

    # stop all threads
    for i in range(args.thread_count):
        input_file_queue.put(None)
        # in thread_job, when input_file_queue.get == None, thread will end
    for t in threads:
        t.join()  # wait till all threads really end

    of_name = join_terms_files(term_files, args)
    terms_to_term_pairs(of_name, args)


if __name__ == '__main__':
    main()
